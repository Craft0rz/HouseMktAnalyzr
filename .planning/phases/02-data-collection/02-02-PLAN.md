---
phase: 02-data-collection
plan: 02
type: execute
---

<objective>
Create a flexible data collection framework with pluggable sources and implement Centris web scraper as the initial data source.

Purpose: Enable property data fetching from multiple sources through a unified interface. Start with scraping (works immediately) while keeping architecture open for API integrations later.
Output: DataSource base class, CentrisScraper implementation, DataCollector orchestrator with caching.
</objective>

<execution_context>
@~/.claude/skills/create-plans/workflows/execute-phase.md
@~/.claude/skills/create-plans/templates/summary.md
</execution_context>

<context>
@.planning/BRIEF.md
@.planning/ROADMAP.md
@.planning/phases/02-data-collection/FINDINGS.md
@src/housemktanalyzr/models/property.py
@src/housemktanalyzr/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DataSource abstract base class</name>
  <files>src/housemktanalyzr/collectors/__init__.py, src/housemktanalyzr/collectors/base.py</files>
  <action>
    Create abstract base class that all data sources must implement:

    ```python
    from abc import ABC, abstractmethod
    from typing import List, Optional
    from ..models.property import PropertyListing

    class DataSource(ABC):
        """Abstract base class for property data sources"""

        name: str  # e.g., "centris", "houski", "repliers"
        priority: int  # lower = higher priority

        @abstractmethod
        async def fetch_listings(
            self,
            region: str,
            property_types: Optional[List[str]] = None,
            min_price: Optional[int] = None,
            max_price: Optional[int] = None,
            limit: Optional[int] = None
        ) -> List[PropertyListing]:
            """Fetch listings matching criteria"""
            pass

        @abstractmethod
        async def get_listing_details(self, listing_id: str) -> Optional[PropertyListing]:
            """Get full details for a single listing"""
            pass

        @abstractmethod
        def is_available(self) -> bool:
            """Check if this source is configured and available"""
            pass
    ```

    Include docstrings explaining the plugin architecture.
  </action>
  <verify>python -c "from housemktanalyzr.collectors.base import DataSource; print('DataSource OK')"</verify>
  <done>Abstract base class importable, defines interface for all sources</done>
</task>

<task type="auto">
  <name>Task 2: Implement CentrisScraper data source</name>
  <files>src/housemktanalyzr/collectors/centris.py</files>
  <action>
    Implement Centris.ca web scraper using httpx and BeautifulSoup:

    - Extend DataSource base class
    - Use httpx for async HTTP requests
    - Parse listing pages for: price, address, bedrooms, bathrooms, property type, sqft, URL
    - Handle pagination (Centris uses infinite scroll / AJAX)
    - Implement rate limiting (1 request per second minimum)
    - Map scraped data to PropertyListing model
    - Set source="centris" on all listings

    Reference existing scrapers:
    - https://github.com/harshhes/centris-ca-scrape
    - https://github.com/enesrizaates/centris.ca-crawler

    Handle common issues:
    - CAPTCHA detection (raise exception, don't retry)
    - Rate limiting (exponential backoff)
    - Missing fields (use None, don't fail)

    Add BeautifulSoup to dependencies if not present.
  </action>
  <verify>python -c "from housemktanalyzr.collectors.centris import CentrisScraper; print('CentrisScraper OK')"</verify>
  <done>Scraper class exists, can be instantiated, implements DataSource interface</done>
</task>

<task type="auto">
  <name>Task 3: Create DataCollector orchestrator</name>
  <files>src/housemktanalyzr/collectors/collector.py</files>
  <action>
    Create unified interface that orchestrates multiple data sources:

    ```python
    class DataCollector:
        """Orchestrates property data collection from multiple sources"""

        def __init__(self, sources: Optional[List[DataSource]] = None):
            # Auto-discover available sources if not provided
            # Sort by priority
            pass

        async def fetch_listings(
            self,
            region: str = "montreal",
            **kwargs
        ) -> List[PropertyListing]:
            """
            Fetch from highest-priority available source.
            Falls back to next source on failure.
            """
            pass

        def add_source(self, source: DataSource) -> None:
            """Register a new data source"""
            pass

        def get_available_sources(self) -> List[str]:
            """List names of available/configured sources"""
            pass
    ```

    Features:
    - Source priority ordering
    - Fallback on source failure
    - Logging of which source was used
    - Simple caching (in-memory dict with TTL)

    Export from collectors/__init__.py for easy import:
    `from housemktanalyzr.collectors import DataCollector, CentrisScraper`
  </action>
  <verify>python -c "from housemktanalyzr.collectors import DataCollector; dc = DataCollector(); print(f'Sources: {dc.get_available_sources()}')"</verify>
  <done>DataCollector works, auto-discovers CentrisScraper, can list available sources</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `pip install -e .` succeeds (with new dependencies)
- [ ] `from housemktanalyzr.collectors import DataSource, DataCollector, CentrisScraper` works
- [ ] DataCollector can be instantiated and lists available sources
- [ ] CentrisScraper implements all DataSource methods
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Flexible plugin architecture ready for additional sources (Houski, Repliers)
- Centris scraper provides initial data collection capability
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-collection/02-02-SUMMARY.md`
</output>
