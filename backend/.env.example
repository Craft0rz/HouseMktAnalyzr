# Backend Configuration
# Copy this file to .env and configure as needed

# Database connection string
DATABASE_URL=postgresql://user:password@host:port/database

# =============================================================================
# Scraper Worker Configuration
# =============================================================================

# How often the scraper runs (in hours, default: 4)
# Recommended: 2 hours for faster updates without overlap
SCRAPER_INTERVAL_HOURS=2

# How long before listings are marked stale (in hours, default: 6)
SCRAPER_TTL_HOURS=6

# Maximum pages to scrape per region/type combination (default: 20)
SCRAPER_MAX_PAGES=20

# Seconds between requests to Centris.ca (default: 1.2)
SCRAPER_REQUEST_INTERVAL=1.2

# Enable/disable background scraper (default: true)
SCRAPER_ENABLED=true

# =============================================================================
# Enrichment Configuration
# =============================================================================

# Detail enrichment (fetching full listing details)
DETAIL_ENRICH_BATCH_SIZE=50
DETAIL_ENRICH_MAX_BATCHES=20
DETAIL_ENRICH_DELAY=1.5

# Walk Score enrichment (geocoding + walk scores)
WALKSCORE_BATCH_SIZE=50
WALKSCORE_MAX_BATCHES=10
WALKSCORE_DELAY=3.0

# Photo fetching
PHOTO_BATCH_SIZE=30
PHOTO_FETCH_DELAY=1.5

# Condition scoring (AI-based condition assessment)
CONDITION_BATCH_SIZE=25
CONDITION_SCORE_DELAY=6.0

# Geo enrichment (schools, parks, flood zones)
# Increased limits to process more houses per cycle now that geocoding is reliable
GEO_ENRICH_BATCH_SIZE=100
GEO_ENRICH_MAX_BATCHES=50
GEO_ENRICH_DELAY=1.0
